{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd4d9e8-15aa-4a0e-bd37-fdd494b17ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 : Loss 4680.3447\n",
      "Iteration 200 : Loss 4579.5776\n",
      "Iteration 300 : Loss 4572.5382\n",
      "Iteration 400 : Loss 4572.0464\n",
      "Iteration 500 : Loss 4572.0121\n",
      "Iteration 600 : Loss 4572.0097\n",
      "Iteration 700 : Loss 4572.0095\n",
      "Iteration 800 : Loss 4572.0095\n",
      "Iteration 900 : Loss 4572.0095\n",
      "Iteration 1000 : Loss 4572.0095\n",
      "Iteration 1100 : Loss 4572.0095\n",
      "Iteration 1200 : Loss 4572.0095\n",
      "Iteration 1300 : Loss 4572.0095\n",
      "Iteration 1400 : Loss 4572.0095\n",
      "Iteration 1500 : Loss 4572.0095\n",
      "Iteration 1600 : Loss 4572.0095\n",
      "Iteration 1700 : Loss 4572.0095\n",
      "Iteration 1800 : Loss 4572.0095\n",
      "Iteration 1900 : Loss 4572.0095\n",
      "Iteration 2000 : Loss 4572.0095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# (1) 데이터셋 불러오기\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# (2) 데이터와 타겟을 분리하기\n",
    "df_X = diabetes.data\n",
    "df_Y = diabetes.target\n",
    "\n",
    "# (3) 훈련셋과 테스트셋 분리하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.2, random_state=36)\n",
    "\n",
    "def model(x, w, b):\n",
    "    y = np.sum(w * x, axis=-1) + b\n",
    "    return y\n",
    "\n",
    "def MSE(a, b):\n",
    "    mse = ((a - b) ** 2).mean()  # 두 값의 차이의 제곱의 평균\n",
    "    return mse\n",
    "\n",
    "def loss(x, w, b, y):\n",
    "    predictions = model(x, w, b)\n",
    "    L = MSE(predictions, y)\n",
    "    return L\n",
    "\n",
    "def gradient(x, w, b, y):\n",
    "    dw = (loss(x, w + 0.0001, b, y) - loss(x, w, b, y)) / 0.0001\n",
    "    db = (loss(x, w, b + 0.0001, y) - loss(x, w, b, y)) / 0.0001\n",
    "    return dw, db\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "losses=[]\n",
    "weight_history=[]\n",
    "bias_history=[]\n",
    "\n",
    "w = np.ones(df_X.shape[1])\n",
    "b = 0\n",
    "\n",
    "for i in range(1, 2001):\n",
    "    dw, db = gradient(X_train, w, b, y_train)   # 3, 4번: 모델이 prediction을 예측하고, 손실함수값을 계산함과 동시에 기울기 계산\n",
    "    w -= lr * dw         # 5번: w = w - η * dw 로 업데이트\n",
    "    b -= lr * db         # 5번: b = b - η * db 로 업데이트 \n",
    "    L = loss(X_train, w, b, y_train)            # 현재의 loss 값 계산\n",
    "    losses.append(L)                # loss 값 기록\n",
    "    if i % 100 == 0:\n",
    "        print('Iteration %d : Loss %0.4f' % (i, L))\n",
    "\n",
    "for epoch in range(2000):\n",
    "    l=0\n",
    "    w_grad=np.zeros(df_X.shape[1])\n",
    "    b_grad=0\n",
    "    \n",
    "    for x,y in zip(X_train,y_train):\n",
    "        l+=loss(x,w,b,y)\n",
    "        w_i, b_i = gradient(x,w,b,y)\n",
    "        w_grad += w_i\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d14bfa-9509-43c0-82fd-bdbc3cdfff85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
