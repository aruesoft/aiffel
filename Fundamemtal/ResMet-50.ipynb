{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83463b5b-b32d-4493-959b-20cd61189938",
   "metadata": {},
   "source": [
    "이번에는 Skip connection이 추가되어 있는 ResNet입니다.\n",
    "\n",
    "Skip connection이 포함된 Residual Block은 어떻게 구현되어 있을까요? 그리고 레이어 수가 많아졌는데 이전 VGG와 어떤 점이 다르게 구현이 되어 있을지 궁금합니다.\n",
    "\n",
    "위에서 ResNet의 구조를 보면 색깔이 서로 다른 블록들이 있습니다. 이는 블록마다 feature의 크기가 서로 다르기 때문인데요. 이렇게 크게 4개의 Stage로 구분해서 생각할 수 있습니다. 하나의 Stage 안에서는 kernel 사이즈와 channel 수가 동일하니, 이런 블록은 일일이 하나씩 짜지 않고 블록 단위로 생성합니다.\n",
    "\n",
    "그렇다면 구현한 방법을 직접 찾아서 정리해 보도록 할까요? 이번에도 Keras ResNet50 코드 구현 소스코드로부터 모델 구현 부분을 가져와 봅시다. 이번 코드는 resnet50() 함수를 이용하면 모델까지 깔끔하게 생성해 주기 때문에 훨씬 가져오기 쉽도록 잘 정리되어 있습니다.\n",
    "\n",
    "코드를 분석해 보면 ResNet50 모델을 생성하기 위해서 반복적으로 활용하는 conv_block과 identity_block이 있을 것입니다. 이런 블록 구조를 잘 활용하여, 50개나 되는 복잡한 레이어 구조를 간결하게 표현하고 있는 것을 확인하실 수 있습니다. 그럼 코드를 활용해볼까요? 데이터셋은 이전 스텝에서 활용했던 CIFAR100을 그대로 활용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3a361f-f3f4-4f93-b0b9-ff25c1c438e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 추가로 import해야 할 패키지들을 먼저 가져옵니다. \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend, regularizers, initializers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e720c-c069-4442-bbdc-4a215f87c0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f704a1d1-02c6-4792-867d-2d8b60e882a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 50000 x_test: 10000\n"
     ]
    }
   ],
   "source": [
    "# CIFAR100 데이터셋을 가져옵시다. \n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(\"x_train:\", len(x_train), \"x_test:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae50660-e266-47b1-b682-555cfaf1109d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf600483-bcfa-47b0-b258-ca61b4122233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# block 안에 반복적으로 활용되는 L2 regularizer를 선언해 줍니다.\n",
    "def _gen_l2_regularizer(use_l2_regularizer=True, l2_weight_decay=1e-4):\n",
    "      return regularizers.l2(l2_weight_decay) if use_l2_regularizer else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a96ba4-c2a8-449a-9b0a-cfe348c6bff0",
   "metadata": {
    "tags": []
   },
   "source": [
    "이어서 반복해서 활용되는 conv_block과 identity_block을 가져와 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2020356e-db93-4169-b611-cfe24d38a931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q. conv_block 함수를 가져옵니다.\n",
    "def conv_block(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(2, 2),\n",
    "               use_l2_regularizer=True,\n",
    "               batch_norm_decay=0.9,\n",
    "               batch_norm_epsilon=1e-5):\n",
    "    \n",
    "    # [[YOUR CODE]]\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      strides=strides,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "    shortcut = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      strides=strides,\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '1')(\n",
    "          input_tensor)\n",
    "    shortcut = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '1')(\n",
    "          shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    ##\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a16c01-2c17-4020-961e-fc9ccc5df7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf96bfa-70be-4900-8849-7d938bc26579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q. identity_block을 가져옵니다.\n",
    "def identity_block(input_tensor,\n",
    "                   kernel_size,\n",
    "                   filters,\n",
    "                   stage,\n",
    "                   block,\n",
    "                   use_l2_regularizer=True,\n",
    "                   batch_norm_decay=0.9,\n",
    "                   batch_norm_epsilon=1e-5):\n",
    "\n",
    "    # [[YOUR CODE]]\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    ##\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41890b5e-2801-4bde-9775-f5f00796234c",
   "metadata": {},
   "source": [
    "자, 이제 resnet50() 함수를 가져올 준비가 다 되었습니다.\n",
    "\n",
    "한 가지만 유의해 주세요. resnet50 모델을 생성하는 함수 안에 Imagenet 데이터셋에 해당하는 input shape가 input_shape = (224, 224, 3)으로 선언되어 있습니다. 우리는 CIFAR100을 다루고 있으니 input_shape = (32, 32, 3)이어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1332e7-ceb8-44de-adfc-12aed0bde398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resnet50(num_classes,\n",
    "             batch_size=None,\n",
    "             use_l2_regularizer=True,\n",
    "             rescale_inputs=False,\n",
    "             batch_norm_decay=0.9,\n",
    "             batch_norm_epsilon=1e-5):\n",
    "    \n",
    "    # [[YOUR CODE]]\n",
    "    input_shape = (32, 32, 3)\n",
    "    img_input = layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        x = layers.Lambda(\n",
    "            lambda x: backend.permute_dimensions(x, (0, 3, 1, 2)),\n",
    "            name='transpose')(\n",
    "                img_input)\n",
    "        bn_axis = 1\n",
    "    else:  # channels_last\n",
    "        x = img_input\n",
    "        bn_axis = 3\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(\n",
    "      64, (7, 7),\n",
    "      strides=(2, 2),\n",
    "      padding='valid',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name='conv1')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=BATCH_NORM_DECAY,\n",
    "      epsilon=BATCH_NORM_EPSILON,\n",
    "      name='bn_conv1')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = conv_block(\n",
    "      x,\n",
    "      3, [64, 64, 256],\n",
    "      stage=2,\n",
    "      block='a',\n",
    "      strides=(1, 1),\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [64, 64, 256],\n",
    "      stage=2,\n",
    "      block='b',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [64, 64, 256],\n",
    "      stage=2,\n",
    "      block='c',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "\n",
    "    x = conv_block(\n",
    "      x,\n",
    "      3, [128, 128, 512],\n",
    "      stage=3,\n",
    "      block='a',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [128, 128, 512],\n",
    "      stage=3,\n",
    "      block='b',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [128, 128, 512],\n",
    "      stage=3,\n",
    "      block='c',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [128, 128, 512],\n",
    "      stage=3,\n",
    "      block='d',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "\n",
    "    x = conv_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='a',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='b',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='c',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='d',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='e',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [256, 256, 1024],\n",
    "      stage=4,\n",
    "      block='f',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "\n",
    "    x = conv_block(\n",
    "      x,\n",
    "      3, [512, 512, 2048],\n",
    "      stage=5,\n",
    "      block='a',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [512, 512, 2048],\n",
    "      stage=5,\n",
    "      block='b',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "    x = identity_block(\n",
    "      x,\n",
    "      3, [512, 512, 2048],\n",
    "      stage=5,\n",
    "      block='c',\n",
    "      use_l2_regularizer=use_l2_regularizer)\n",
    "\n",
    "    rm_axes = [1, 2] if backend.image_data_format() == 'channels_last' else [2, 3]\n",
    "    x = layers.Lambda(lambda x: backend.mean(x, rm_axes), name='reduce_mean')(x)\n",
    "    x = layers.Dense(\n",
    "      num_classes,\n",
    "      kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      bias_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name='fc1000')(\n",
    "          x)\n",
    "\n",
    "    # A softmax that is followed by the model loss must be done cannot be done\n",
    "    # in float16 due to numeric issues. So we pass dtype=float32.\n",
    "    x = layers.Activation('softmax', dtype='float32')(x)\n",
    "\n",
    "    \n",
    "    ##\n",
    "    # Create model.\n",
    "    return models.Model(img_input, x, name='resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9e37c-ad8d-415e-8b08-8617cebb6296",
   "metadata": {},
   "source": [
    "resnet50() 가 드디어 완성되었습니다. 이제 이를 활용해서 우리의 model을 만들어 봅시다.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f7bd9e1-5a99-46ea-ba5e-ce82d38a7b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_input = keras.Input(shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe524c1-d2a5-4c93-aef2-5448bb5c8f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fae33-3189-4493-b16f-2a5406c8c337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa90e68-dcd8-47e3-afdb-a22f182abe82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b204c57-5069-4636-aac3-3a6939c03577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24055ca5-84f2-4b5e-b809-96249973a711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c282f708-c284-4fa7-97aa-d6af2509135e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mresnet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mresnet50\u001b[0;34m(num_classes, batch_size, use_l2_regularizer, rescale_inputs, batch_norm_decay, batch_norm_epsilon)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresnet50\u001b[39m(num_classes,\n\u001b[1;32m      2\u001b[0m              batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m              use_l2_regularizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# [[YOUR CODE]]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     img_input \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mimage_data_format() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     13\u001b[0m         x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLambda(\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m x: backend\u001b[38;5;241m.\u001b[39mpermute_dimensions(x, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m     15\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m'\u001b[39m)(\n\u001b[1;32m     16\u001b[0m                 img_input)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "model = resnet50(num_classes=100)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa48404-65c3-447f-92d1-b6a8796c3d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
