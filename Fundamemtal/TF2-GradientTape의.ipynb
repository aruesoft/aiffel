{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b911fd1-b7d5-453a-91ac-6d19af82521f",
   "metadata": {},
   "source": [
    "## GradientTape의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a71811-8d79-4765-9bbc-62a922c558f1",
   "metadata": {},
   "source": [
    "#### Automatic differentiation - GradientTape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0301c-66f5-4f0e-bca5-20a9c93e9ce7",
   "metadata": {},
   "source": [
    "Numpy만 가지고 딥러닝을 구현하는 것을 회상해 봅시다. model.fit()이라는 한 줄로 수행 가능한 딥러닝 모델 훈련 과정은 실제로는 어떠했나요?\n",
    "  \n",
    "1. Forward Propagation 수행 및 중간 레이어값 저장\n",
    "2. Loss 값 계산\n",
    "3. 중간 레이어값 및 Loss를 활용한 체인룰(chain rule) 방식의 역전파(Backward Propagation) 수행\n",
    "4. 학습 파라미터 업데이트\n",
    "\n",
    "이상 4단계로 이루어진 train_step 을 여러 번 반복했습니다.  \n",
    "  \n",
    "이런 과정이 TF2 API에는 model.fit()이라는 메서드 안에 모두 추상화되어 감추어져 있습니다.  \n",
    "\n",
    "Tensorflow에서 제공하는 tf.GradientTape는 위와 같이 순전파(forward pass) 로 진행된 모든 연산의 중간 레이어값을 tape에 기록하고,   \n",
    "이를 이용해 gradient를 계산한 후 tape를 폐기하는 기능을 수행합니다.   \n",
    "그러면 아래에서는 이전 스텝에서 진행했던 학습을 tf.GradientTape를 이용한 것으로 변형해 보겠습니다.   \n",
    "아래에서 할 tf.GradientTape는 이후 그래디언트를 좀 더 고급스럽게 활용하는 다양한 기법을 통해 자주 만나게 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affe5e38-e7a5-4d68-99e7-8827c9687780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n",
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d56aa-8c8b-4fc4-8fbf-d3ae6475da70",
   "metadata": {
    "tags": []
   },
   "source": [
    "여기까지는 앞에서 다루었던 Subclassing을 활용한 모델 작성법과 전혀 다르지 않습니다.\n",
    "달라지는 것은 model.compile(), model.fit()을 통해 손쉽게 진행했던 학습 세팅 및 수행 부분입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41d8e9-b099-4739-b502-1e64ab5797b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "'''\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d198a-172a-47b3-9162-c4dc02e76c08",
   "metadata": {
    "tags": []
   },
   "source": [
    "위와 같이 모델 학습을 위해 loss, optimizer를 지정해 주면 내부적으로는 매 스텝 학습이 진행될 때마다 발생하는 loss 및 그래디언트가 어떻게 학습 파라미터를 업데이트하게 되는지를 지정해 주는 작업이 model.compile() 안에서 자동으로 진행되었습니다.  \n",
    "\n",
    "아래 코드는 tape.gradient()를 통해 매 스텝 학습이 진행될 때마다 발생하는 그래디언트를 추출한 후 optimizer.apply_gradients()를 통해 발생한 그래디언트가 업데이트해야 할 파라미터 model.trainable_variables를 지정해 주는 과정을 기술한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f515f02-b27f-4fac-a12b-8087d7628b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af67ad-af50-416f-868e-891ff82ba4d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "위와 같이 매 스텝 진행되는 학습의 실제 동작이 train_step() 메서드로 구현되었습니다.\n",
    "\n",
    " - model.fit(x_train, y_train, epochs=5, batch_size=32)  \n",
    "    \n",
    "이 model.fit()으로 위와 같이 한 줄로 간단하게 수행되던 실제 배치 학습 과정은,  \n",
    "다름 아니라 매 스텝마다 위에서 구현했던 train_step()가 호출되는 과정으로 바꾸어 구현할 수 있습니다.  \n",
    "model.fit() 호출 시에 결정되는 batch_size만 이번 스텝에서 결정해 주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5990023e-9154-4359-9ca3-a45721e9010e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 3.0454\n",
      "Epoch 1: last batch loss = 2.5197\n",
      "Epoch 2: last batch loss = 2.3166\n",
      "Epoch 3: last batch loss = 2.1735\n",
      "Epoch 4: last batch loss = 1.9544\n",
      "It took 69.65213537216187 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            x_batch.append(x)\n",
    "            y_batch.append(y)\n",
    "            if step % batch_size == batch_size-1:\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d63ab-0043-46fb-8791-a063055eb852",
   "metadata": {
    "tags": []
   },
   "source": [
    "어떻습니까? 위에서 구현한 train_model() 메서드가 실은 우리가 그동안 사용했던 model.fit() 메서드와 기능적으로 같다는 것이 확인되시나요?  \n",
    "\n",
    "\n",
    "이렇듯 tf.GradientTape()를 활용하면 model.compile()과 model.fit() 안에 감추어져 있던 한 스텝의 학습 단계(위 예제에서는 train_step 메서드)를 끄집어내서 자유롭게 재구성할 수 있게 됩니다.   \n",
    "\n",
    "그동안 흔히 다루어 왔던 지도학습 방식과 다른 강화학습 또는 GAN(Generative Advasarial Network)의 학습을 위해서는 train_step 메서드의 재구성이 필수적이므로 tf.GradientTape()의 활용법을 꼭 숙지해 두셔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbc3e48-2c4c-4104-ac47-d28f6c2397cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 16:22:40.501926: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3379"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1237f88-2681-483b-8fc8-2210b70649de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Visible devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_visible_devices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGPU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/framework/config.py:547\u001b[0m, in \u001b[0;36mset_visible_devices\u001b[0;34m(devices, device_type)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.set_visible_devices\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    515\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.set_visible_devices\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_endpoints(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.set_visible_devices\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_visible_devices\u001b[39m(devices, device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Set the list of visible devices.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m  Specifies which `PhysicalDevice` objects are visible to the runtime.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 547\u001b[0m   \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_visible_devices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1624\u001b[0m, in \u001b[0;36mContext.set_visible_devices\u001b[0;34m(self, devices, device_type)\u001b[0m\n\u001b[1;32m   1621\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1625\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisible devices cannot be modified after being initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visible_device_list \u001b[38;5;241m=\u001b[39m visible_device_list\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Visible devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6b6dd-520a-4f81-b2c8-56e105af6dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
