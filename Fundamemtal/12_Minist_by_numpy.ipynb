{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a694771-5c8a-42df-8be1-c9e9fed95c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f30538b4-b17d-4bdd-af50-b5af9a66c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf8a17c-fb15-4759-812b-776a7136a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e76c430-7675-4cb4-95d3-12839c275a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9c6752-b49b-41fd-8974-7ddce8e78b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638214f4-b615-4b9c-9f7e-bd1d6d195986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee83c6ac-267c-4f41-a413-2ed910647127",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0935f44a-2929-4279-9b1f-f2228c6fb9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화 ? \n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f697f8-3b40-4f0d-a1bf-b3bb037375f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1743f4-5e6d-4a9a-b40a-0a90c4c0aa55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd6462e-2056-45a4-ba85-dcbd43170a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력 , dot : 행렬곱 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b72faa8-983e-455b-9962-56c0d4333f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1.shape:(784, 50) : 인접 레이어간 관계 나타내는 파라미터\n",
      "X.shape:(5, 784)  : 인풋 값\n",
      "b1.shape:(50,) : bias parameter\n",
      "a1.shape:(5, 50) : (은닉층)\n"
     ]
    }
   ],
   "source": [
    "print('W1.shape:{} : 인접 레이어간 관계 나타내는 파라미터'.format(W1.shape))\n",
    "print('X.shape:{}  : 인풋 값'.format(X.shape))\n",
    "print('b1.shape:{} : bias parameter'.format(b1.shape))\n",
    "print('a1.shape:{} : (은닉층)'.format(a1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41c7def5-49e0-4ad4-b39d-ee605f58cb19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40969909 0.4780367  0.55549474 0.47533048 0.1226221  0.57734689\n",
      " 0.32620675 0.46843504 0.62801602 0.51026387 0.48359554 0.47160468\n",
      " 0.60402354 0.67258598 0.70872806 0.3517376  0.30344372 0.6701429\n",
      " 0.58602843 0.36882563 0.71878955 0.50230475 0.27902201 0.79458623\n",
      " 0.64137042 0.83653965 0.06388716 0.30146292 0.59702953 0.93512102\n",
      " 0.45715317 0.38208308 0.8075804  0.46605151 0.50517457 0.54271896\n",
      " 0.44856744 0.42127238 0.26071155 0.83811965 0.83402485 0.46258909\n",
      " 0.33592118 0.38980843 0.27522965 0.30401636 0.62350722 0.17254492\n",
      " 0.57924997 0.55469875]\n"
     ]
    }
   ],
   "source": [
    "# Numpy\n",
    "# ext : exp 함수는 자연 상수 e의 x 제곱 값을 계산해주는 함수입니다. e는 약 2.71828로, 수학적으로 중요한 상수입니다. x 값에 따라 결과값이 크게 변합니다. x가 양수인 경우 결과값이 점점 커지고, 음수인 경우 결과값이 점점 작아집니다.\n",
    "\n",
    "예를 들어, exp(1)은 e의 1제곱을 계산하여 약 2.71828이 됩니다. 또한, exp(-1)은 e의 -1제곱을 계산하여 약 0.36788이 됩니다. exp 함수는 주로 확률 계산, 지수 함수와 관련된 수식, 머신러닝 등에서 사용됩니다.\n",
    "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 element가 0에서 1사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be5ce04a-deec-47fd-bc26-2d6e0a48bedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "619e04e5-6271-475c-93da-71cfff776063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.23197957 -0.16533228 -0.01257295 -0.01980828 -0.16725585  0.16754595\n",
      "  0.08031149 -0.13923419  0.21737013  0.46333025]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76faa2f8-c8b5-44f9-9174-ac6299536889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebad2cd7-0932-4dc5-bbfe-bd4f5e91681a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11579451, 0.07782832, 0.09067346, 0.09001977, 0.07767875,\n",
       "       0.10856874, 0.09949915, 0.07988622, 0.11411512, 0.14593596])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d06b4cc-1721-498b-953a-1e430b8d240f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_one_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_one_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e735a14e-2663-4252-8d0e-e60dc1d45898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11579451 0.07782832 0.09067346 0.09001977 0.07767875 0.10856874\n",
      " 0.09949915 0.07988622 0.11411512 0.14593596]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7fb0657-d8e3-4679-b10e-7e7cb473ca40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2234837053114536"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457157d9-3603-45a8-939e-08fc7bfd136e",
   "metadata": {},
   "source": [
    "X-Y 좌표축의 기울기란 X의 변화에 따른 Y의 변화량을 의미합니다.\n",
    "Y를 X로 미분해서 구하지요.\n",
    "\n",
    "우리는 파라미터 W의 변화에 따른 오차(Loss) L의 변화량을 구하려고 합니다. \n",
    "그러면 오차 기울기가 커지는 방향의 반대 방향으로 파라미터를 조정해 주면 됩니다. \n",
    "단, 조정을 너무 많이 해주면 안 되기 때문에 적절한 step size 역할을 하는 learning rate가 필수적입니다.\n",
    "그 과정을 Numpy를 통해 구현해 보겠습니다\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "916dc3a8-4b3b-4c8c-ae79-965aeb0c8584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0231589 ,  0.01556566,  0.01813469,  0.01800395,  0.01553575,\n",
       "        -0.17828625,  0.01989983,  0.01597724,  0.02282302,  0.02918719],\n",
       "       [-0.1744187 ,  0.01647559,  0.020092  ,  0.01676362,  0.01708868,\n",
       "         0.01827082,  0.02384309,  0.0165788 ,  0.02110274,  0.02420336],\n",
       "       [ 0.01956854,  0.01695509,  0.01609279,  0.01844714, -0.18579513,\n",
       "         0.02254229,  0.02344842,  0.01330711,  0.02512853,  0.03030522],\n",
       "       [ 0.01860023, -0.18292094,  0.01726501,  0.01913076,  0.01434541,\n",
       "         0.02125701,  0.02312842,  0.01288163,  0.02468118,  0.03163129],\n",
       "       [ 0.0219918 ,  0.017583  ,  0.0153116 ,  0.01845695,  0.01319414,\n",
       "         0.02020265,  0.02148487,  0.01380497,  0.02270388, -0.16473387]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c6d62fa-1d35-4694-91ed-c27bf88ef59c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "#dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "deb194fc-b7c5-42be-8660-576358c07896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "424931fa-5f31-4f25-bd58-2e186478cb83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "907f0c55-a105-4d96-9576-c9f4a35a7ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ac84063-a476-492b-baf7-7300aa08edd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db248ce2-2848-4dcc-b17d-0d7cce039b36",
   "metadata": {},
   "source": [
    "backPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b508a002-5e2c-474b-bcc4-5cee05925276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cd9e786-610e-49e7-8880-413e58d49264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06576426 0.09035934 0.12743167 0.0724405  0.13635358 0.10359503\n",
      "  0.11730042 0.1000583  0.12420202 0.06249489]\n",
      " [0.07606983 0.08528226 0.10845392 0.06604837 0.13474525 0.11003996\n",
      "  0.12495271 0.10730389 0.12496396 0.06213985]\n",
      " [0.07022802 0.08928499 0.09778169 0.08113852 0.10470959 0.11637719\n",
      "  0.09376612 0.12171368 0.15039375 0.07460644]\n",
      " [0.06256311 0.07210534 0.12760216 0.06289305 0.15901344 0.10640032\n",
      "  0.10702223 0.12239998 0.12202856 0.05797182]\n",
      " [0.05595216 0.07967916 0.13013205 0.08354202 0.15001531 0.11504139\n",
      "  0.09942496 0.10214236 0.11995343 0.06411716]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.495320917164009\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_one_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7d632cb-afcf-46fc-a37c-440dd34889cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_one_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        print(y_hat)\n",
    "        print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adbdd0f5-9219-4404-ab65-574e85c5f525",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "[[0.09236903 0.09657525 0.07634385 0.07900484 0.13660977 0.07588111\n",
      "  0.12569022 0.18092852 0.05372159 0.08287582]\n",
      " [0.08006172 0.10415488 0.06237974 0.07930751 0.15039766 0.0856675\n",
      "  0.11164213 0.18692942 0.05945226 0.08000717]\n",
      " [0.08395383 0.10813766 0.06291858 0.0772277  0.15298903 0.06783926\n",
      "  0.11507906 0.18823689 0.06818133 0.07543665]\n",
      " [0.06957422 0.09634504 0.05978168 0.07898502 0.14186913 0.08026622\n",
      "  0.12159811 0.19284597 0.06528002 0.09345458]\n",
      " [0.06646181 0.10609495 0.04970261 0.06562071 0.15846614 0.07175694\n",
      "  0.12494733 0.22221849 0.0661137  0.06861731]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.3999927654280206\n",
      "---------\n",
      "[[0.10992482 0.10902204 0.07041008 0.07177389 0.14684834 0.09458559\n",
      "  0.10858691 0.13919244 0.05018888 0.09946701]\n",
      " [0.10082826 0.1159406  0.05796885 0.07167243 0.1608966  0.10219133\n",
      "  0.09534771 0.14262828 0.05465966 0.09786627]\n",
      " [0.09920816 0.12238631 0.05811492 0.06969905 0.17321084 0.07995638\n",
      "  0.09879455 0.14396257 0.06263745 0.09202976]\n",
      " [0.08152743 0.11472226 0.05559782 0.07197693 0.15257067 0.09488589\n",
      "  0.10517908 0.14864301 0.06091566 0.11398127]\n",
      " [0.08068837 0.12381909 0.04661038 0.05961365 0.17448708 0.08610474\n",
      "  0.10771022 0.16843887 0.0611252  0.09140239]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.192711443309009\n",
      "---------\n",
      "[[0.12500006 0.11790957 0.06380359 0.06434608 0.15146831 0.11252364\n",
      "  0.09375117 0.11181001 0.04610708 0.11328048]\n",
      " [0.12083344 0.12351821 0.05286138 0.06395169 0.16487175 0.11617091\n",
      "  0.08136441 0.11390192 0.04940066 0.11312562]\n",
      " [0.11193154 0.13258541 0.05272097 0.06206154 0.18798104 0.08998464\n",
      "  0.08469601 0.11484278 0.0565762  0.10661987]\n",
      " [0.09122917 0.13069842 0.05076995 0.06470343 0.15737887 0.10708181\n",
      "  0.09086438 0.1194813  0.05586384 0.13192883]\n",
      " [0.09260784 0.1369952  0.04258091 0.05303916 0.18252526 0.09774487\n",
      "  0.09216138 0.13284439 0.05514801 0.11435298]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.034535286293769\n",
      "---------\n",
      "[[0.13783826 0.12419415 0.05747268 0.05753306 0.15282694 0.12971246\n",
      "  0.08146589 0.0925385  0.04211768 0.12430036]\n",
      " [0.14002057 0.12813792 0.04789021 0.05696447 0.16519723 0.12793023\n",
      "  0.06992274 0.0938942  0.04441872 0.12562371]\n",
      " [0.12238373 0.13980978 0.04755477 0.05513929 0.19950279 0.09817845\n",
      "  0.07309433 0.09441055 0.05084716 0.11907915]\n",
      " [0.09895264 0.14489725 0.04607818 0.05802295 0.15881857 0.11715912\n",
      "  0.07901408 0.0989404  0.050951   0.14716582]\n",
      " [0.10232596 0.14668122 0.0384725  0.046871   0.18569855 0.10693885\n",
      "  0.0790915  0.1077802  0.04927995 0.13686027]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.9081706647263847\n",
      "---------\n",
      "[[0.14867158 0.1286104  0.05174772 0.05154478 0.15241952 0.14618784\n",
      "  0.07139279 0.07831479 0.03845592 0.13265465]\n",
      " [0.15836943 0.13071487 0.04335549 0.05089206 0.16365364 0.13776736\n",
      "  0.06065042 0.07925789 0.03995366 0.13538517]\n",
      " [0.13081016 0.14489056 0.04289587 0.04912206 0.20931809 0.10476756\n",
      "  0.06365691 0.07941543 0.04572407 0.1293993 ]\n",
      " [0.10495127 0.15786561 0.04180508 0.05216177 0.15848885 0.12540029\n",
      "  0.0693237  0.08380648 0.04647514 0.15972181]\n",
      " [0.11001322 0.15378354 0.03463355 0.04140709 0.18610661 0.1139793\n",
      "  0.06832553 0.08936043 0.04392808 0.15846265]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.8035671051950484\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복 돌립니다.\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601298e-4128-46f1-8eb8-c9094799b3ff",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fdb254d-cff8-4b09-9f90-2b58a7571e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "098ae7da-e471-4bb8-a74e-8c1d4fd80563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15773553, 0.13170041, 0.04670236, 0.04637105, 0.15112585,\n",
       "       0.16201234, 0.06311526, 0.06744765, 0.03518633, 0.13860322])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82a226c4-b7d6-4d68-8626-d86c65fe08fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9853b76-b238-4693-9c85-972d070bc6c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15773553 0.13170041 0.04670236 0.04637105 0.15112585 0.16201234\n",
      " 0.06311526 0.06744765 0.03518633 0.13860322]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.17\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_one_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d0697-dc55-4007-8dc7-9c7ad3db2261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
